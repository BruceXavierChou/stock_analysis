{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BruceXavierChou/stock_analysis/blob/main/%E3%80%8Cstk_ch02_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFQ17AmL0Yd0"
      },
      "source": [
        "# CH-02 å¾é›¶é–‹å§‹çš„ OpenAI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a42M4mg1qNQ5"
      },
      "source": [
        "## 2-3 å»ºæ§‹è‡ªå·±çš„ AI æ©Ÿå™¨äºº"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwGTl75BLNwu"
      },
      "source": [
        "### 1ï¸âƒ£ ä½¿ç”¨ OpenAI API å®˜æ–¹å¥—ä»¶\n",
        "\n",
        "OpenAI å®˜æ–¹æä¾›æœ‰ openai å¥—ä»¶, å¯ä»¥ç°¡åŒ–ä½¿ç”¨ä¸Šçš„è¤‡é›œåº¦ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9x1F86C4T9u",
        "outputId": "36f61eba-4ca6-4a69-f290-0ab90ea38b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.14-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.14\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGukHBkyiQA2"
      },
      "source": [
        "### 2ï¸âƒ£ è¼¸å…¥ API KEY\n",
        "getpass å¥—ä»¶å¯ä»¥éš±è—è¼¸å…¥å€¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN8CnE789cPy",
        "outputId": "b39df8b1-45cb-4c03-e252-c999c9289cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "è«‹è¼¸å…¥é‡‘é‘°ï¼šÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI, OpenAIError # OpenAI å®˜æ–¹å¥—ä»¶\n",
        "import getpass # ä¿å¯†è¼¸å…¥å¥—ä»¶\n",
        "api_key = getpass.getpass(\"è«‹è¼¸å…¥é‡‘é‘°ï¼š\")\n",
        "client = OpenAI(api_key = api_key) # å»ºç«‹ OpenAI ç‰©ä»¶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC1gzHDLiqhT"
      },
      "source": [
        "### 3ï¸âƒ£ å»ºæ§‹æ¨¡å‹ä¸¦äº¤è«‡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBkpRomPEXd1"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    # model = \"gpt-4\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"ä½ ä½çš„åœ°æ–¹å¾ˆäº®å—ï¼Ÿ\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyelatvvLiIn"
      },
      "source": [
        "### 4ï¸âƒ£ æª¢è¦–å‚³å›ç‰©ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSjownHrGnde",
        "outputId": "9f588c7f-7b7b-4440-bfa2-f6a809c5eded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-9lWKpOUN5Iffqh9GowVWqRXoLST0m', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='å°ä¸èµ·ï¼Œæˆ‘ç„¡æ³•å›ç­”é€™å€‹å•é¡Œï¼Œå› ç‚ºä½œç‚ºä¸€å€‹èªè¨€æ¨¡å‹AIï¼Œæˆ‘ç„¡æ³•çŸ¥é“ä½ ä½çš„åœ°æ–¹çš„å…‰ç·šæƒ…æ³ã€‚å¦‚æœä½ éœ€è¦çš„è©±ï¼Œæˆ‘å¯ä»¥å¹«ä½ è§£ç­”é—œæ–¼å…‰ç·šå’Œç…§æ˜çš„ç›¸é—œå•é¡Œã€‚æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«åŠ©ä½ çš„å—ï¼Ÿ', role='assistant', function_call=None, tool_calls=None))], created=1721112739, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=111, prompt_tokens=21, total_tokens=132))\n"
          ]
        }
      ],
      "source": [
        "print(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkoAWO2GjnlT"
      },
      "source": [
        "### 5ï¸âƒ£ æª¢è¦–è¨Šæ¯å…§å®¹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDHvn0VCGPzH",
        "outputId": "432cbc90-fd77-4cd1-dddf-3e8414bd7380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å°ä¸èµ·ï¼Œæˆ‘ç„¡æ³•å›ç­”é€™å€‹å•é¡Œï¼Œå› ç‚ºä½œç‚ºä¸€å€‹èªè¨€æ¨¡å‹AIï¼Œæˆ‘ç„¡æ³•çŸ¥é“ä½ ä½çš„åœ°æ–¹çš„å…‰ç·šæƒ…æ³ã€‚å¦‚æœä½ éœ€è¦çš„è©±ï¼Œæˆ‘å¯ä»¥å¹«ä½ è§£ç­”é—œæ–¼å…‰ç·šå’Œç…§æ˜çš„ç›¸é—œå•é¡Œã€‚æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«åŠ©ä½ çš„å—ï¼Ÿ\n"
          ]
        }
      ],
      "source": [
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP5FkDxALp4e"
      },
      "source": [
        "### 6ï¸âƒ£ è¨­å®š AI è§’è‰²"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1x0glPsNJe2",
        "outputId": "03828544-0df4-4a40-af1b-417212a50d2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ˜¯çš„ï¼Œæˆ‘ä½çš„åœ°æ–¹éå¸¸äº®ï¼Œå› ç‚ºå‘¨åœéƒ½æ˜¯æ˜Ÿæ˜Ÿå’Œè¡Œæ˜Ÿï¼Œå®‡å®™ä¸­å……æ»¿è‘—å„ç¨®ç¥ç§˜çš„å…‰èŠ’ã€‚é€™è£¡çš„å¤œç©ºè®“äººæ„Ÿåˆ°ç„¡æ¯”å¯§éœå’Œç¾éº—ã€‚\n"
          ]
        }
      ],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [\n",
        "        {\"role\":\"system\", \"content\":\"ä½ æ˜¯éš»ä½åœ¨å¤–å¤ªç©ºçš„çŒ´å­\"},\n",
        "        {\"role\":\"user\", \"content\": \"ä½ ä½çš„åœ°æ–¹å¾ˆäº®å—ï¼Ÿ reply in ç¹é«”ä¸­æ–‡\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuqEE9zwkxHx"
      },
      "source": [
        "### 7ï¸âƒ£ å¯«æˆå‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48eLL4VEQGza"
      },
      "outputs": [],
      "source": [
        "def get_reply(messages):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model = \"gpt-3.5-turbo\",\n",
        "            messages = messages\n",
        "        )\n",
        "        reply = response.choices[0].message.content\n",
        "    except OpenAIError as err:\n",
        "        reply = f\"ç™¼ç”Ÿ {err.error.type} éŒ¯èª¤\\n{err.error.message}\"\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyB85LMUcHai"
      },
      "source": [
        "### 8ï¸âƒ£ ç°¡æ˜“çš„å°è«‡ç¨‹å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMBhPuFwcH4G"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    msg = input(\"ä½ èªªï¼š\")\n",
        "    if not msg.strip(): break\n",
        "    messages = [{\"role\":\"user\", \"content\":msg}]\n",
        "    reply = get_reply(messages)\n",
        "    print(f\"ã„Ÿå”‰ï¼š{reply}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xyG43Miczix"
      },
      "source": [
        "### 9ï¸âƒ£ è¨˜æ†¶å°è©±ç´€éŒ„çš„å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daLnk-UGczqX"
      },
      "outputs": [],
      "source": [
        "hist = []       # æ­·å²å°è©±ç´€éŒ„\n",
        "backtrace = 2   # è¨˜éŒ„å¹¾çµ„å°è©±\n",
        "\n",
        "def chat(sys_msg, user_msg):\n",
        "    hist.append({\"role\":\"user\", \"content\":user_msg})\n",
        "    reply = get_reply(hist\n",
        "                      + [{\"role\":\"system\", \"content\":sys_msg}])\n",
        "    while len(hist) >= 2 * backtrace: # è¶…éè¨˜éŒ„é™åˆ¶\n",
        "        hist.pop(0)                   # ç§»é™¤æœ€èˆŠç´€éŒ„\n",
        "    hist.append({\"role\":\"assistant\", \"content\":reply})\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgQuQjVLc5wU"
      },
      "source": [
        "### ğŸ”Ÿ èƒ½æ¥çºŒå°è©±çš„ AI ç¨‹å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "dKjDWUWAc59I",
        "outputId": "0c05977c-4a17-4ac0-d416-c0221ccc9ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ä½ å¸Œæœ›ã„Ÿå”‰æ‰®æ¼”ï¼šå°åŠ©ç†\n",
            "\n",
            "ä½ èªªï¼šè‡ºç£åœ¨å“ªè£¡?\n",
            "å°åŠ©ç†:è‡ºç£ä½æ–¼äºæ´²æ±éƒ¨ï¼Œè¥¿è‡¨ä¸­åœ‹å¤§é™¸ï¼Œæ±æ¿±å¤ªå¹³æ´‹ã€‚\n",
            "\n",
            "ä½ èªªï¼šé¢ç©å¤šå°‘?\n",
            "å°åŠ©ç†:è‡ºç£çš„é¢ç©ç´„æœ‰36,000å¹³æ–¹å…¬é‡Œã€‚\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-99a36106a4cc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ä½ èªªï¼š\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "sys_msg = input(\"ä½ å¸Œæœ›ã„Ÿå”‰æ‰®æ¼”ï¼š\")\n",
        "if not sys_msg.strip(): sys_msg = 'å°åŠ©ç†'\n",
        "print()\n",
        "while True:\n",
        "    msg = input(\"ä½ èªªï¼š\")\n",
        "    if not msg.strip(): break\n",
        "    reply = chat(sys_msg, msg)\n",
        "    print(f\"{sys_msg}:{reply}\\n\")\n",
        "hist = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAX-IFIYHrlH"
      },
      "source": [
        "### 1ï¸âƒ£1ï¸âƒ£ å®‰è£èˆ‡åŒ¯å…¥ google æœå°‹å¥—ä»¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htKR8b20udnQ",
        "outputId": "35a1fa8a-373c-45b2-aa99-e6a2abdb8827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch_python-1.2.4-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (4.12.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2024.7.4)\n",
            "Installing collected packages: googlesearch-python\n",
            "Successfully installed googlesearch-python-1.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install googlesearch-python\n",
        "from googlesearch import search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx_Hs7E172Ko"
      },
      "source": [
        "### 1ï¸âƒ£2ï¸âƒ£ ä½¿ç”¨ google æœå°‹å¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd1BRQ_m8UBx",
        "outputId": "87cf44b0-c830-4e8d-c0da-ae3d06421128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NBA In-Season Tournament | Official Site\n",
            "The official site for the latest news, schedules, groups, format, rules and FAQs for the 2023 NBA In-Season Tournament.\n",
            "https://www.nba.com/in-season-tournament/2023\n",
            "\n",
            "2023 In-Season Tournament | Bracket\n",
            "The official bracket of the 2023 NBA In-Season Tournament.\n",
            "https://www.nba.com/in-season-tournament/2023/bracket\n",
            "\n",
            "2023 In-Season Tournament | Bracket\n",
            "The official bracket of the 2023 NBA In-Season Tournament.\n",
            "https://www.nba.com/in-season-tournament/2023/bracket\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for item in search(\n",
        "    \"NBA 2023 å† è»éšŠ\", advanced=True, num_results=3):\n",
        "    print(item.title)\n",
        "    print(item.description)\n",
        "    print(item.url)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndwQg9wVx7eN"
      },
      "source": [
        "### 1ï¸âƒ£3ï¸âƒ£ å°‡æœå°‹çµæœåŠ å…¥åˆ° content ä¸­"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47Ya7BkDucsR"
      },
      "outputs": [],
      "source": [
        "hist = []       # æ­·å²å°è©±ç´€éŒ„\n",
        "backtrace = 2   # è¨˜éŒ„å¹¾çµ„å°è©±\n",
        "\n",
        "def chat_w(sys_msg, user_msg, search_g = True):\n",
        "    web_res = []\n",
        "    if search_g == True: # ä»£è¡¨è¦æœå°‹ç¶²è·¯\n",
        "        content = \"ä»¥ä¸‹ç‚ºå·²ç™¼ç”Ÿçš„äº‹å¯¦ï¼š\\n\"\n",
        "        for res in search(user_msg, advanced=True,\n",
        "                          num_results=3, lang='zh-TW'):\n",
        "            content += f\"æ¨™é¡Œï¼š{res.title}\\n\" \\\n",
        "                       f\"æ‘˜è¦ï¼š{res.description}\\n\\n\"\n",
        "        content += \"è«‹ä¾ç…§ä¸Šè¿°äº‹å¯¦å›ç­”å•é¡Œ \\n\"\n",
        "        web_res = [{\"role\": \"user\", \"content\": content}]\n",
        "    web_res.append({\"role\": \"user\", \"content\": user_msg})\n",
        "    while len(hist) >= 2 * backtrace: # è¶…éè¨˜éŒ„é™åˆ¶\n",
        "        hist.pop(0)  # ç§»é™¤æœ€èˆŠçš„ç´€éŒ„\n",
        "    reply_full = \"\"\n",
        "    for reply in get_reply(\n",
        "        hist                          # å…ˆæä¾›æ­·å²ç´€éŒ„\n",
        "        + web_res                     # å†æä¾›æœå°‹çµæœåŠç›®å‰è¨Šæ¯\n",
        "        + [{\"role\": \"system\", \"content\": sys_msg}]):\n",
        "        reply_full += reply           # è¨˜éŒ„åˆ°ç›®å‰ç‚ºæ­¢æ”¶åˆ°çš„è¨Šæ¯\n",
        "        yield reply                   # å‚³å›æœ¬æ¬¡æ”¶åˆ°çš„ç‰‡æ®µè¨Šæ¯\n",
        "    hist.append({\"role\": \"user\", \"content\": user_msg})\n",
        "    while len(hist) >= 2 * backtrace: # è¶…éè¨˜éŒ„é™åˆ¶\n",
        "        hist.pop(0)                   # ç§»é™¤æœ€èˆŠç´€éŒ„\n",
        "    hist.append({\"role\":\"assistant\", \"content\":reply_full})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ItD6pYlyMjS"
      },
      "source": [
        "### 1ï¸âƒ£4ï¸âƒ£ çªç ´æœå°‹é™åˆ¶çš„èŠå¤©æ©Ÿå™¨äºº"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZKP6M_fuvqv"
      },
      "outputs": [],
      "source": [
        "sys_msg = 'å°åŠ©ç†'\n",
        "\n",
        "while True:\n",
        "    msg = input(\"ä½ èªªï¼š\")\n",
        "    if not msg.strip(): break\n",
        "    print(f\"{sys_msg}ï¼š\", end = \"\")\n",
        "    for reply in chat_w(sys_msg, msg, search_g = True):\n",
        "        print(reply, end = \"\")\n",
        "    print('\\n')\n",
        "hist = []"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}